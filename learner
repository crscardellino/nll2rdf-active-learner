#!/usr/bin/env perl

# NLL2RDF Active Learner
# Copyright (C) 2014 Cristian A. Cardellino
#
# This program is free software: you can redistribute it and/or modify
# it under the terms of the GNU General Public License as published by
# the Free Software Foundation, either version 3 of the License, or
# (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program.  If not, see <http://www.gnu.org/licenses/>.

use strict;
use warnings;
use File::Spec;
use Getopt::Long;
use Statistics::Descriptive;
use Statistics::Descriptive::Weighted;

sub print_help {
  print STDERR "usage:\n";
  print STDERR "./learner -t <TAGGED_DIR> -u <UNTAGGED_DIR> -o <OUTPUT_DIR> ";
  print STDERR "[-q <NUMBER_OF_QUERIES>] [-f <FILTER_TAGGED_CORPUS>] [-g <FILTER_UNTAGGED_CORPUS>] [--passive]\n";
  print STDERR "\tTAGGED_DIR\t\tDirectory with the annotated files in conll format\n";
  print STDERR "\tUNTAGGED_DIR\t\tDirectory with the unannotated files in conll format\n";
  print STDERR "\tOUTPUT_DIR\t\tDirectory where results are written\n";
  print STDERR "\tNUMBER_OF_QUERIES\tAmount of queries in each step of the Active Learning algorithm (defaults to 5)\n";
  print STDERR "\tFILTER_TAGGED_CORPUS\tFilter of features for annotated corpus (default to 0)\n";
  print STDERR "\tFILTER_UNTAGGED_CORPUS\tFilter of features for unannotated corpus (default to 10)\n";
  print STDERR "\tpassive\t\t\tIf flagged, the sampling of the unannotated corpus is random (doesn't use active learning approach)\n";
}

sub print_results {
  my $iteration = shift;
  my $dir = shift;

  my @data = `find $dir -name "data.*.txt" -print0 | xargs -0 -I {} sh -c 'printf {}; printf " "; cat {}'`;
  die "$!" if ($? >> 8) != 0;
  chomp @data;

  my @kappas = ();
  my @precisions = ();
  my @recalls = ();
  my @fmeasures = ();
  my @weights = ();

  open(my $fh, ">", "$dir/generalresults.txt") or die "$!";

  print "\nResults for iteration $iteration\n";
  print $fh "\nResults for iteration $iteration\n";
  print "KAPPA\tPREC\tRECALL\tF-SCORE\tCLASS\n";
  print $fh "KAPPA\tPREC\tRECALL\tF-SCORE\tCLASS\n";

  foreach my $data(@data) {
    my @coeffs = split /\s/, $data;
    my ($volume, $directory, $filename) = File::Spec->splitpath(shift @coeffs);
    
    my $name = (split /\./, $filename)[1];

    print $coeffs[0] . "\t" . $coeffs[1] . "\t" . $coeffs[2] . "\t" . $coeffs[3] . "\t";
    print $fh $coeffs[0] . "\t" . $coeffs[1] . "\t" . $coeffs[2] . "\t" . $coeffs[3] . "\t";
    print uc($name) . "\n";
    print $fh uc($name) . "\n";
    push @kappas, $coeffs[0];
    push @precisions, $coeffs[1];
    push @recalls, $coeffs[2];
    push @fmeasures, $coeffs[3];
    push @weights, $coeffs[4];
  }

  my @stats = ();
  my @wstats = ();
  
  my $stat = Statistics::Descriptive::Full->new();
  $stat->add_data(@kappas);
  push @stats, $stat;
  my $wstat = Statistics::Descriptive::Weighted::Full->new();
  $wstat->add_data(\@kappas, \@weights);
  push @wstats, $wstat;

  $stat = Statistics::Descriptive::Full->new();
  $stat->add_data(@precisions);
  push @stats, $stat;
  $wstat = Statistics::Descriptive::Weighted::Full->new();
  $wstat->add_data(\@precisions, \@weights);
  push @wstats, $wstat;

  $stat = Statistics::Descriptive::Full->new();
  $stat->add_data(@recalls);
  push @stats, $stat;
  $wstat = Statistics::Descriptive::Weighted::Full->new();
  $wstat->add_data(\@recalls, \@weights);
  push @wstats, $wstat;

  $stat = Statistics::Descriptive::Full->new();
  $stat->add_data(@fmeasures);
  push @stats, $stat;
  $wstat = Statistics::Descriptive::Weighted::Full->new();
  $wstat->add_data(\@fmeasures, \@weights);
  push @wstats, $wstat;

  print "\nGeneral Results Stastistics\n";
  print "KAPPA\tPREC\tRECALL\tF-SCORE\tCLASS\n";

  print sprintf("%.2f\t", $wstats[0]->median());
  print sprintf("%.2f\t", $wstats[1]->median());
  print sprintf("%.2f\t", $wstats[2]->median());
  print sprintf("%.2f\t", $wstats[3]->median());
  print "WEIGHTED MEAN\n";

  print sprintf("%.2f\t", $stats[0]->median());
  print sprintf("%.2f\t", $stats[1]->median());
  print sprintf("%.2f\t", $stats[2]->median());
  print sprintf("%.2f\t", $stats[3]->median());
  print "MEDIAN\n";

  print sprintf("%.2f\t", $stats[0]->mean());
  print sprintf("%.2f\t", $stats[1]->mean());
  print sprintf("%.2f\t", $stats[2]->mean());
  print sprintf("%.2f\t", $stats[3]->mean());
  print "MEAN\n";
  
  print sprintf("%.2f\t", $stats[0]->standard_deviation());
  print sprintf("%.2f\t", $stats[1]->standard_deviation());
  print sprintf("%.2f\t", $stats[2]->standard_deviation());
  print sprintf("%.2f\t", $stats[3]->standard_deviation());
  print "SDEV\n";

  print $fh "\nGeneral Results Stastistics\n";
  print $fh "KAPPA\tPREC\tRECALL\tF-SCORE\tCLASS\n";

  print $fh sprintf("%.2f\t", $wstats[0]->median());
  print $fh sprintf("%.2f\t", $wstats[1]->median());
  print $fh sprintf("%.2f\t", $wstats[2]->median());
  print $fh sprintf("%.2f\t", $wstats[3]->median());
  print $fh "WEIGHTED MEAN\n";

  print $fh sprintf("%.2f\t", $stats[0]->median());
  print $fh sprintf("%.2f\t", $stats[1]->median());
  print $fh sprintf("%.2f\t", $stats[2]->median());
  print $fh sprintf("%.2f\t", $stats[3]->median());
  print $fh "MEDIAN\n";

  print $fh sprintf("%.2f\t", $stats[0]->mean());
  print $fh sprintf("%.2f\t", $stats[1]->mean());
  print $fh sprintf("%.2f\t", $stats[2]->mean());
  print $fh sprintf("%.2f\t", $stats[3]->mean());
  print $fh "MEAN\n";
  
  print $fh sprintf("%.2f\t", $stats[0]->standard_deviation());
  print $fh sprintf("%.2f\t", $stats[1]->standard_deviation());
  print $fh sprintf("%.2f\t", $stats[2]->standard_deviation());
  print $fh sprintf("%.2f\t", $stats[3]->standard_deviation());
  print $fh "SDEV\n";

  close $fh;
}

my $tagdir = undef;
my $untagdir = undef;
my $outputdir = undef;
my $query_instances = 5;
my $tagfilter = 0;
my $untagfilter = 10;
my $passive = '';

print STDERR "NLL2RDF Active Learner Copyright (C) 2014 Cristian A. Cardellino\n";
print STDERR "This program comes with ABSOLUTELY NO WARRANTY.\n";
print STDERR "This is free software, and you are welcome to redistribute it under certain conditions.\n";
print STDERR "See LICENSE for details, or visit <http://www.gnu.org/licenses/gpl.html>.\n\n";

GetOptions("t=s" => \$tagdir,
           "u=s" => \$untagdir,
           "o=s" => \$outputdir,
           "q=i" => \$query_instances,
           "f=i" => \$tagfilter,
           "g=i" => \$untagfilter,
           "passive" => \$passive);

if(!defined $tagdir or !defined $untagdir or !defined $outputdir) {
  print_help;
  die "Error in parsing the arguments.";
} 

mkdir "$outputdir/iteration0";
mkdir "$outputdir/iteration0/data";
mkdir "$outputdir/iteration0/data/binary";
mkdir "$outputdir/iteration0/models";
mkdir "$outputdir/iteration0/features";
mkdir "$outputdir/iteration0/results";

my $rc = system "perl ./utils/annotated/generateannotatedfile.pl $tagdir $outputdir/iteration0 $tagfilter";
die if ($rc >> 8) != 0;

print STDERR "Annotated corpus initial training\n";

my $java = "java -Xmx2048m -cp bin/nll2rdf.jar nll2rdf.classifiers.AnnotatedClassifier";
my $args = "-a $outputdir/iteration0/data/binary/ -o $outputdir/iteration0/";

$rc = system $java . " " . $args;
die "Error in the training of the initial model: $!" if ($rc >> 8) != 0;

print_results 0, "$outputdir/iteration0/results";

print "\n";

my $iteration = 1;

while(!$passive) {
  print STDERR "\nActive learning iteration: $iteration\n";

  my $outdir = "$outputdir/iteration$iteration";
  mkdir "$outdir";
  mkdir "$outdir/data";
  mkdir "$outdir/data/binary";
  mkdir "$outdir/instances";
  mkdir "$outdir/instances/tagged";
  mkdir "$outdir/models";
  mkdir "$outdir/features";
  mkdir "$outdir/results";

  my $olddir = sprintf("$outputdir/iteration%d", $iteration - 1);
  my $featuresdir = "$olddir/features";
  my $modelsdir = "$olddir/models";
  my $oldarff = "$olddir/data/annotated.nll2rdf.arff";

  $rc = system "perl ./utils/unannotated/generateunannotatedfile.pl $untagdir $featuresdir $oldarff $outdir $untagfilter";
  die if ($rc >> 8) != 0;

  my $instance_count = `wc -l $outdir/data/unannotated.nll2rdf.csv | awk '{ print \$1 }'`;
  chomp $instance_count;

  my $java = "java -Xmx2048m -cp bin/nll2rdf.jar nll2rdf.classifiers.UnannotatedClassifier";
  my $args = "-c $outdir/data/unannotated.nll2rdf.csv -m $modelsdir/ -o $outdir/ -a $oldarff -i $instance_count -q $query_instances";

  $rc = system $java . " " . $args;
  die "Error in the querying: $!" if ($rc >> 8) != 0;

  print STDERR "\nQueries Annotation\n";

  $rc = system "perl ./utils/activelearning/makequeries.pl $outdir/data/queries.txt $outdir/instances";
  die "Error in query annotation: $!" if ($rc >> 8) != 0;

  print STDERR "Classifier retrain\n";

  my $rc = system "perl ./utils/annotated/generateannotatedfile.pl $tagdir $outdir $tagfilter $olddir";
  die if ($rc >> 8) != 0;

  $java = "java -Xmx2048m -cp bin/nll2rdf.jar nll2rdf.classifiers.AnnotatedClassifier";
  $args = "-a $outdir/data/binary/ -o $outdir/";

  $rc = system $java . " " . $args;
  die "Error in the training of the initial model: $!" if ($rc >> 8) != 0;

  print_results $iteration, "$outdir/results";

  print "Continue? [y/N]: ";
  my $ans = <STDIN>;

  last unless $ans =~ m/^[yY]/;
  $iteration++;
}

while($passive) {
  print STDERR "\nPassive learning iteration: $iteration\n";

  my $outdir = "$outputdir/iteration$iteration";
  mkdir "$outdir";
  mkdir "$outdir/data";
  mkdir "$outdir/data/binary";
  mkdir "$outdir/instances";
  mkdir "$outdir/instances/tagged";
  mkdir "$outdir/models";
  mkdir "$outdir/features";
  mkdir "$outdir/results";

  my $olddir = sprintf("$outputdir/iteration%d", $iteration - 1);
  my $featuresdir = "$olddir/features";
  my $modelsdir = "$olddir/models";
  my $oldarff = "$olddir/data/annotated.nll2rdf.arff";

  $rc = system "perl ./utils/unannotated/generateunannotatedfile.pl $untagdir $featuresdir $oldarff $outdir $untagfilter";
  die "$!" if ($rc >> 8) != 0;

  $rc = system "perl ./utils/activelearning/randomqueries.pl $outdir/data/queries.txt $outdir/data/unannotated.nll2rdf.csv $query_instances";
  die "$!" if ($rc >> 8) != 0;

  print STDERR "\nQueries Annotation\n";

  $rc = system "perl ./utils/activelearning/makequeries.pl $outdir/data/queries.txt $outdir/instances";
  die "Error in query annotation: $!" if ($rc >> 8) != 0;

  print STDERR "\nClassifier retrain\n";

  my $rc = system "perl ./utils/annotated/generateannotatedfile.pl $tagdir $outdir $tagfilter $olddir";
  die if ($rc >> 8) != 0;

  $java = "java -Xmx2048m -cp bin/nll2rdf.jar nll2rdf.classifiers.AnnotatedClassifier";
  $args = "-a $outdir/data/binary/ -o $outdir/";

  $rc = system $java . " " . $args;
  die "Error in the training of the initial model: $!" if ($rc >> 8) != 0;

  print_results $iteration, "$outdir/results";

  print "Continue? [y/N]: ";
  my $ans = <STDIN>;

  last unless $ans =~ m/^[yY]/;
  $iteration++;
}